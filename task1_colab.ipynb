{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MegaVictinixyz/CS771-Course-Project/blob/main/task1_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***1. Import data and libraries***"
      ],
      "metadata": {
        "id": "cA-U8awdVzH1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOrwiQ4ChaND",
        "outputId": "31e721c2-3b49-42d4-8320-0f7f8982f842",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=16hB6UKRYC45BzAby92-eG19fLZ-rTqlA\n",
            "From (redirected): https://drive.google.com/uc?id=16hB6UKRYC45BzAby92-eG19fLZ-rTqlA&confirm=t&uuid=d535d75c-41c3-44de-a715-0c616651c907\n",
            "To: /content/dataset.zip\n",
            "100% 301M/301M [00:07<00:00, 41.9MB/s]\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 301067282 bytes (288 MiB)\n",
            "\n",
            "Extracting archive: dataset.zip\n",
            "--\n",
            "Path = dataset.zip\n",
            "Type = zip\n",
            "Physical Size = 301067282\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Would you like to replace the existing file:\n",
            "  Path:     ./dataset/.DS_Store\n",
            "  Size:     8196 bytes (9 KiB)\n",
            "  Modified: 2024-10-29 16:26:33\n",
            "with the file from archive:\n",
            "  Path:     dataset/.DS_Store\n",
            "  Size:     8196 bytes (9 KiB)\n",
            "  Modified: 2024-10-29 16:26:33\n",
            "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? "
          ]
        }
      ],
      "source": [
        "#Downloading dataset\n",
        "!gdown https://drive.google.com/uc?id=16hB6UKRYC45BzAby92-eG19fLZ-rTqlA\n",
        "!7z x dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import all libraries used\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.spatial.distance import mahalanobis\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
      ],
      "metadata": {
        "id": "MqhAbY7gr44e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "eval=[]\n",
        "for i in range(1,11):\n",
        "  eval_path = '/content/dataset/part_one_dataset/eval_data/' + str(i) + '_eval_data.tar.pth'\n",
        "  eval.append(torch.load(eval_path))\n",
        "data=[]\n",
        "for i in range(1,11):\n",
        "  data_path = '/content/dataset/part_one_dataset/train_data/' + str(i) + '_train_data.tar.pth'\n",
        "  data.append(torch.load(data_path))"
      ],
      "metadata": {
        "id": "rI8P5WRwpdXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a0d59b-d231-42d3-f04e-6a92c29a484f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-5013b179767f>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  eval.append(torch.load(eval_path))\n",
            "<ipython-input-3-5013b179767f>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data.append(torch.load(data_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***2. Feature extraction and pre-processing***"
      ],
      "metadata": {
        "id": "HERa0MvbWQtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create separated list of datasets and labels\n",
        "X = []\n",
        "Y = []\n",
        "XV = []\n",
        "YV = []\n",
        "for i in range(10):\n",
        "    X.append(data[i]['data'])\n",
        "    XV.append(eval[i]['data'])\n",
        "    if(i==0):\n",
        "      Y.append(data[i]['targets'])\n",
        "    YV.append(eval[i]['targets'])"
      ],
      "metadata": {
        "id": "DLlHA7VxrGU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoFeatureExtractor, AutoModel\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# Load feature extractor and model\n",
        "model_name = \"google/vit-base-patch16-224-in21k\"\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Define transformations to resize images from X to 224x224\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
        "])\n",
        "\n",
        "# Custom Dataset class for your image dataset X\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, images, transform=None):\n",
        "        self.images = images\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.fromarray(self.images[idx].astype(np.uint8)) # Assuming your image data is uint8 type\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# Function to extract features\n",
        "def extract_features(data_loader, model):\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for images in data_loader:\n",
        "            # Move images to device (GPU if available)\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model.to(device)\n",
        "            images = images.to(device)\n",
        "\n",
        "            # Extract features from the model\n",
        "            outputs = model(images)\n",
        "            # Use `outputs.last_hidden_state.mean(dim=1)` for mean pooled features\n",
        "            # Or use `outputs.pooler_output` for [CLS] token representation\n",
        "            features_batch = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "            features.append(features_batch)\n",
        "\n",
        "    # Combine features into a single numpy array\n",
        "    features = np.vstack(features)\n",
        "    return features"
      ],
      "metadata": {
        "id": "GE8BiUKif7-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract\n",
        "ext_feat = []\n",
        "ext_feat_val = []\n",
        "\n",
        "for dataset in X:\n",
        "  batch_size = 32\n",
        "  dataset = CustomImageDataset(dataset, transform=transform)\n",
        "  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "  features = extract_features(data_loader, model)\n",
        "  ext_feat.append(features)\n",
        "\n",
        "for dataset in XV:\n",
        "  batch_size = 32\n",
        "  dataset = CustomImageDataset(dataset, transform=transform)\n",
        "  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "  features = extract_features(data_loader, model)\n",
        "  ext_feat_val.append(features)"
      ],
      "metadata": {
        "id": "FvJvxFyj1tQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ext_feat[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjVNIfeRgSKp",
        "outputId": "21066f02-3495-45c3-c1c0-1bce009952c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape in correct shape (2500,768)\n",
        "X_feat=[0]*10\n",
        "X_feat_val=[0]*10\n",
        "for i in range(10):\n",
        "   X_feat[i]=ext_feat[i].reshape(2500,-1)\n",
        "   X_feat_val[i]=ext_feat_val[i].reshape(2500,-1)"
      ],
      "metadata": {
        "id": "ENb6cCtKyWFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dimentionality reduction for data\n",
        "\n",
        "#Perform LDA\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_feat[0], Y[0])\n",
        "for i in range(10):\n",
        "  X_feat[i] = lda.transform(X_feat[i])\n",
        "  X_feat_val[i] = lda.transform(X_feat_val[i])"
      ],
      "metadata": {
        "id": "hPACmySmWf2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_feat[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svpUi_bChsMa",
        "outputId": "6c103aee-01e1-43b2-e5f3-1b7afaddf5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***3. Simple LwP with Mahalanobis distance***"
      ],
      "metadata": {
        "id": "9pvTTuvXWjv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Manhatten distance\n",
        "#W = Inverce Covariance matrix of dataset 1\n",
        "W = np.linalg.pinv(np.cov(X_feat[0].T))\n",
        "def dist(x,y):\n",
        "  return np.dot(np.dot((x-y).T,W),(x-y))"
      ],
      "metadata": {
        "id": "ms061cQGXHo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Class means of 1st dataset: Our F1\n",
        "def create_f1(X,Y):\n",
        "  class_means = []\n",
        "  class_counts = []\n",
        "  for class_label in range(10):\n",
        "    class_indices = np.where(Y == class_label)[0]\n",
        "    class_counts.append(len(class_indices))\n",
        "    if len(class_indices) > 0:\n",
        "      class_samples = X[class_indices]\n",
        "      class_mean = np.mean(class_samples, axis=0)\n",
        "      class_means.append(class_mean)\n",
        "\n",
        "  class_means = np.array(class_means)\n",
        "  return class_means, class_counts"
      ],
      "metadata": {
        "id": "UwM429A0yf0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple LwP and model updation\n",
        "def simple_LwP(X_feat,Y,f1, class_counts):\n",
        "  models=[]\n",
        "  for i in range(10):\n",
        "    models.append([0]*10)\n",
        "  models[0] = f1\n",
        "\n",
        "  predicted_labels=[]\n",
        "  for i in range(10):\n",
        "    predicted_labels.append([])\n",
        "  predicted_labels[0]=Y[0]\n",
        "  for i in range(9):\n",
        "    for sample in X_feat[i+1]:\n",
        "      distances = [dist(sample , mean) for mean in models[i]]\n",
        "      predicted_label = np.argmin(distances)\n",
        "      predicted_labels[i+1].append(predicted_label)\n",
        "\n",
        "    for class_label in range(10):\n",
        "      class_indices = [j for j in range(2500) if predicted_labels[i+1][j] == class_label]\n",
        "\n",
        "      if len(class_indices) > 0:\n",
        "        class_samples = X_feat[i+1][class_indices]\n",
        "        class_mean = np.mean(class_samples, axis=0)\n",
        "        models[i+1][class_label] = (class_mean * len(class_indices) + models[i][class_label] * class_counts[class_label] ) / ( len(class_indices) + class_counts[class_label] )\n",
        "\n",
        "      class_counts[class_label]+=len(class_indices)\n",
        "\n",
        "  return models\n",
        "\n",
        "#Predict labels a dataset X using a model\n",
        "def predict(model,X):\n",
        "  predicted_labels = [0]*2500\n",
        "  for i in range(2500):\n",
        "    distances = [dist(X[i] , mean) for mean in model]\n",
        "    label = np.argmin(distances)\n",
        "    predicted_labels[i]=label\n",
        "  return predicted_labels"
      ],
      "metadata": {
        "id": "26dEzGM2Zg-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get first model and others via updation\n",
        "f1, class_counts = create_f1(X_feat[0],Y[0])\n",
        "all_models = simple_LwP(X_feat,Y,f1,class_counts)"
      ],
      "metadata": {
        "id": "V_KIe5gWoOiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction Table for simple_LwP\n",
        "table = [[0 for i in range(10)] for j in range(10)]\n",
        "for i in range(10):\n",
        "  for j in range(i+1):\n",
        "    validation_accuracy = accuracy_score(YV[j], predict(all_models[i],X_feat_val[j]))\n",
        "    table[i][j]=validation_accuracy*100"
      ],
      "metadata": {
        "id": "jjJMoCjpKqEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print table\n",
        "simple_LwP_table = pd.DataFrame(table)\n",
        "simple_LwP_table.index = ['f'+str(i) for i in range(1,11)]\n",
        "simple_LwP_table.columns = ['D'+str(i) for i in range(1,11)]\n",
        "print(simple_LwP_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rMIWwqoLz25",
        "outputId": "ff98c056-9018-4c22-ad96-98f7fc46c8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        D1     D2     D3     D4     D5     D6     D7     D8     D9   D10\n",
            "f1   96.08   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.0\n",
            "f2   96.04  96.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.0\n",
            "f3   96.00  96.04  95.92   0.00   0.00   0.00   0.00   0.00   0.00   0.0\n",
            "f4   95.96  96.04  95.96  95.56   0.00   0.00   0.00   0.00   0.00   0.0\n",
            "f5   96.00  96.04  95.92  95.60  96.52   0.00   0.00   0.00   0.00   0.0\n",
            "f6   96.00  96.04  95.92  95.60  96.52  96.40   0.00   0.00   0.00   0.0\n",
            "f7   96.00  96.04  95.92  95.60  96.52  96.36  95.52   0.00   0.00   0.0\n",
            "f8   95.92  96.04  95.92  95.60  96.56  96.36  95.52  95.68   0.00   0.0\n",
            "f9   96.00  96.04  95.92  95.60  96.56  96.36  95.52  95.68  95.72   0.0\n",
            "f10  95.92  96.04  95.92  95.56  96.56  96.36  95.52  95.68  95.72  96.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***4. Gaussian Mixture Model***"
      ],
      "metadata": {
        "id": "ZI878N5bMm_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gaussian Mixture Model\n",
        "def GMM(X,Y):\n",
        "  #Returns distribution (mean, variance) and prior (class counts)\n",
        "  class_means = []\n",
        "  class_counts = []\n",
        "  for class_label in range(10):\n",
        "    class_indices = np.where(Y == class_label)[0]\n",
        "    class_counts.append(len(class_indices))\n",
        "    if len(class_indices) > 0:\n",
        "      class_samples = X[class_indices]\n",
        "      class_mean = np.mean(class_samples, axis=0)\n",
        "      class_means.append(class_mean)\n",
        "\n",
        "  class_means = np.array(class_means)\n",
        "\n",
        "  COV=np.array([[[0.0 for j in range(len(X[0]))] for i in range(len(X[0]))] for k in range(10)])\n",
        "  for i in range(2500):\n",
        "    COV[Y[i]]+=np.outer(X[i]-class_means[Y[i]],X[i]-class_means[Y[i]])\n",
        "  for k in range(10):\n",
        "    COV[k]/=class_counts[k]\n",
        "\n",
        "  return class_means,COV,class_counts\n",
        "\n",
        "#Generate samples from learned distribution\n",
        "def Generate_samples(recall,class_means,COV,class_counts,threshold):\n",
        "  generated_samples = []\n",
        "  N = sum(class_counts)\n",
        "  for k in range(10):\n",
        "    det = np.linalg.det(COV[k])\n",
        "    inv = np.linalg.pinv(COV[k])\n",
        "    i = 0\n",
        "    while i<((recall*class_counts[k])//N):\n",
        "      sample = np.random.multivariate_normal(class_means[k], COV[k])\n",
        "      if np.log(class_counts[k]) - (0.5)*np.log(np.abs(det)) - (0.5)*((sample-class_means[k]).T @ (inv) @ (sample-class_means[k])) > threshold:\n",
        "        generated_samples.append(sample)\n",
        "        i+=1\n",
        "  generated_samples = np.array(generated_samples)\n",
        "  return generated_samples\n",
        "\n",
        "#Predict on a dataset X\n",
        "def predict_gmm(X,class_means,COV,class_counts):\n",
        "  predicted_probs = [[0 for k in range(10)] for i in range(2500)]\n",
        "  for k in range(10):\n",
        "    det = np.linalg.det(COV[k])\n",
        "    inv = np.linalg.pinv(COV[k])\n",
        "    for i in range(2500):\n",
        "      predicted_probs[i][k] = np.log(class_counts[k]) - (0.5)*np.log(np.abs(det)) - (0.5)*((X[i]-class_means[k]).T @ (inv) @ (X[i]-class_means[k]))\n",
        "\n",
        "  predicted_labels = [0]*2500\n",
        "\n",
        "  for i in range(2500):\n",
        "    predicted_labels[i] = np.argmax(predicted_probs[i])\n",
        "\n",
        "  predicted_labels = np.array(predicted_labels)\n",
        "  return predicted_labels"
      ],
      "metadata": {
        "id": "lzfWc4-lPixL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall = 2500 #Recall for generating samples\n",
        "threshold = -5 #For generating better samples (score >-5 only)\n",
        "\n",
        "#Model creating and updation and prediction\n",
        "class_means,COV,class_counts = GMM(X_feat[0],Y[0])\n",
        "table = [[0 for i in range(10)] for j in range(10)]\n",
        "table[0][0] = accuracy_score(YV[0], predict_gmm(X_feat_val[0],class_means,COV,class_counts))*100\n",
        "for i in range(1,10):\n",
        "  generated_samples = Generate_samples(recall*i,class_means,COV,class_counts,threshold)\n",
        "  Union_data = np.concatenate((X_feat_val[i],generated_samples),axis=0)\n",
        "  Union_labels = predict_gmm(Union_data,class_means,COV,class_counts)\n",
        "  class_means,COV,class_counts = GMM(Union_data,Union_labels)\n",
        "  for j in range(i+1):\n",
        "    validation_accuracy = accuracy_score(YV[j], predict_gmm(X_feat_val[j],class_means,COV,class_counts))\n",
        "    table[i][j]=validation_accuracy*100"
      ],
      "metadata": {
        "id": "gl8X_A2WTONB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print table\n",
        "GMM_table = pd.DataFrame(table)\n",
        "GMM_table.index = ['f'+str(i) for i in range(1,11)]\n",
        "GMM_table.columns = ['D'+str(i) for i in range(1,11)]\n",
        "print(GMM_table)"
      ],
      "metadata": {
        "id": "YXEglrONM4aA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b30d0c8-c9bb-4dc9-f49b-799c5f100196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        D1     D2     D3     D4     D5     D6     D7     D8     D9    D10\n",
            "f1   95.84   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00\n",
            "f2   95.72  96.12   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00\n",
            "f3   95.04  95.56  95.48   0.00   0.00   0.00   0.00   0.00   0.00   0.00\n",
            "f4   94.36  95.60  95.20  95.12   0.00   0.00   0.00   0.00   0.00   0.00\n",
            "f5   93.76  95.48  94.84  94.56  95.16   0.00   0.00   0.00   0.00   0.00\n",
            "f6   93.64  95.12  94.56  94.44  94.96  95.00   0.00   0.00   0.00   0.00\n",
            "f7   93.88  94.96  94.64  94.28  94.76  94.56  95.12   0.00   0.00   0.00\n",
            "f8   93.60  94.80  94.16  94.40  95.00  94.52  95.28  93.88   0.00   0.00\n",
            "f9   93.40  94.72  94.16  94.24  94.60  94.52  94.84  93.60  93.88   0.00\n",
            "f10  93.24  94.24  93.80  94.20  94.28  94.48  94.52  93.32  93.56  94.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-EnjwyxPdNHu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}